services:
  ollama:
    image: ollama/ollama:latest
    container_name: eventify-ollama
    restart: unless-stopped
    profiles:
      - llm
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - monorepo-network
    environment:
      - OLLAMA_NUM_PARALLEL=1
      - OLLAMA_MAX_LOADED_MODELS=1
    # Resource limits to prevent memory issues
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: "1.0"

  api:
    container_name: eventify-api-prod
    restart: unless-stopped
    build:
      context: .
      target: production
    ports:
      - 4001:3007
    volumes:
      - ./uploads:/usr/src/eventify/uploads
    working_dir: /usr/src/eventify
    env_file:
      - .env
    # Resource limits for production (3.8GB server)
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "0.5"
    networks:
      - monorepo-network
    command: node dist/apps/api/main

  batch:
    container_name: eventify-batch-prod
    restart: unless-stopped
    build:
      context: .
      target: production
    ports:
      - 4002:3008
    volumes:
      - ./uploads:/usr/src/eventify/uploads
      - /var/run/docker.sock:/var/run/docker.sock
    env_file:
      - .env
    # Resource limits for production (3.8GB server)
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "0.5"
    networks:
      - monorepo-network
    profiles:
      - batch
    command: sh -c "apk add --no-cache docker-cli && node dist/apps/batch/main"

volumes:
  ollama_data:

networks:
  monorepo-network:
    driver: bridge
